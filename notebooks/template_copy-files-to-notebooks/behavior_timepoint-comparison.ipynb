{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Behavior Analysis: Comparison of Timepoints"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e03de428c1b3db0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Press SHIFT + ENTER to run code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd6a360bf17b7d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### USER INPUT!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb7624fdfd93586"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca9fb2a33975a1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T18:05:12.304317Z",
     "start_time": "2025-01-11T18:05:12.300300Z"
    }
   },
   "outputs": [],
   "source": [
    "## Define project\n",
    "project_name = ''\n",
    "\n",
    "selected_groups = []\n",
    "selected_conditions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Main Code: Create Individual CSVs for Timepoint Comparisons (Fraction Time in Behavior; Bouts/Min; Mean Bout Duration) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6e3371ebb588a7a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### Continue to Press SHIFT + ENTER to run code ###\n",
    "\n",
    "# Prompt user for input\n",
    "num_timepoints = int(input(\"Enter the number of time ranges you want to compare (e.g., 2, 3, etc.): \"))\n",
    "time_ranges = [] # Enter the time ranges IN MINUTES (e.g., 0-10 for 0 to 10 minutes, then 11-30 for remaining 11-30 minutes)\n",
    "\n",
    "for i in range(num_timepoints):\n",
    "    time_range = input(f\"Time range {i + 1}: \")\n",
    "    try:\n",
    "        start_min, end_min = map(int, time_range.split('-'))\n",
    "        if start_min >= end_min:\n",
    "            print(f\"Error: Start time ({start_min}) must be less than end time ({end_min}).\")\n",
    "            exit()\n",
    "        start_sec, end_sec = start_min * 60, end_min * 60\n",
    "        time_ranges.append((start_sec, end_sec))\n",
    "    except ValueError:\n",
    "        print(\"Invalid input format. Please enter the time range as 'start-end' (e.g., 0-10).\")\n",
    "        exit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9784f94f6e6142b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Individual File Comparisons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa223f09c0bbda86"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Combined_CSO19_CSO19_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Bins: [0, 660, 1800]\n",
      "Time Labels: ['0-10 min', '11-30 min']\n",
      "Saved analysis for Combined_CSO19_CSO19_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv to ../processed_dataset/project_ACC_MiniscopeSNI_Male_Psilo_1Week/figures/behavior_timepoint_comparison/analysis_Combined_CSO19_CSO19_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Processing file: Combined_CSO17_CSO17_1WeekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Bins: [0, 660, 1800]\n",
      "Time Labels: ['0-10 min', '11-30 min']\n",
      "Saved analysis for Combined_CSO17_CSO17_1WeekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv to ../processed_dataset/project_ACC_MiniscopeSNI_Male_Psilo_1Week/figures/behavior_timepoint_comparison/analysis_Combined_CSO17_CSO17_1WeekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Warning: Maximum time (842.9833333333333s) in Combined_MM98_MM98_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv is less than the final bin end (1800s).\n",
      "Processing file: Combined_MM98_MM98_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Bins: [0, 660, 842.9833333333333]\n",
      "Time Labels: ['0-10 min', '11-30 min']\n",
      "Saved analysis for Combined_MM98_MM98_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv to ../processed_dataset/project_ACC_MiniscopeSNI_Male_Psilo_1Week/figures/behavior_timepoint_comparison/analysis_Combined_MM98_MM98_1weekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Processing file: Combined_CSO15_CSO15_1WeekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Bins: [0, 660, 1800]\n",
      "Time Labels: ['0-10 min', '11-30 min']\n",
      "Saved analysis for Combined_CSO15_CSO15_1WeekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv to ../processed_dataset/project_ACC_MiniscopeSNI_Male_Psilo_1Week/figures/behavior_timepoint_comparison/analysis_Combined_CSO15_CSO15_1WeekPsilDLC_resnet50_LUPE_MALEDec5shuffle1_350000.csv\n",
      "Behavior analysis completed for all files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Validate the time ranges\n",
    "if len(time_ranges) < 2:\n",
    "    print(\"Error: At least two time ranges are required for comparison.\")\n",
    "    exit()\n",
    "\n",
    "bins = [start for start, end in time_ranges] + [time_ranges[-1][1]]\n",
    "time_labels = [f\"{start//60}-{end//60} min\" for start, end in time_ranges]\n",
    "\n",
    "# Directory containing the per-second CSV files\n",
    "input_dir = f'../processed_dataset/{project_name}/figures/behaviors_csv_raw-classification/seconds'\n",
    "\n",
    "# Directory to save the analysis results\n",
    "analysis_dir = f'../processed_dataset/{project_name}/figures/behavior_timepoint_comparison'\n",
    "os.makedirs(analysis_dir, exist_ok=True)\n",
    "\n",
    "def calculate_behavior_metrics(data, frame_rate=60):\n",
    "    metrics = {}\n",
    "    unique_behaviors = data['behavior'].unique()\n",
    "\n",
    "    for behavior in unique_behaviors:\n",
    "        behavior_data = data[data['behavior'] == behavior]\n",
    "        \n",
    "        fraction_time = len(behavior_data) / len(data)\n",
    "\n",
    "        bout_starts = (behavior_data.index.to_series().diff() > 1).cumsum()\n",
    "        bouts = behavior_data.groupby(bout_starts)\n",
    "\n",
    "        bouts_per_minute = len(bouts) / (len(data) / frame_rate / 60)\n",
    "\n",
    "        mean_bout_duration = bouts.size().mean() / frame_rate\n",
    "\n",
    "        metrics[behavior] = {\n",
    "            'Fraction Time': fraction_time,\n",
    "            'Bouts per Minute': bouts_per_minute,\n",
    "            'Mean Bout Duration (s)': mean_bout_duration\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Processing each file\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith('.csv'):\n",
    "        \n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        max_time = df['time_seconds'].max()\n",
    "        \n",
    "        bins = [start for start, end in time_ranges] + [time_ranges[-1][1]]\n",
    "        if max_time < bins[-1]:\n",
    "            print(f\"Warning: Maximum time ({max_time}s) in {file_name} is less than the final bin end ({bins[-1]}s).\")\n",
    "            bins[-1] = max_time\n",
    "\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "        print(f\"Bins: {bins}\")\n",
    "        print(f\"Time Labels: {time_labels}\")\n",
    "        \n",
    "        try:\n",
    "            df['time_group'] = pd.cut(df['time_seconds'], \n",
    "                                      bins=bins,\n",
    "                                      labels=time_labels,\n",
    "                                      right=False)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in pd.cut for file {file_name}: {e}\")\n",
    "            continue \n",
    "        \n",
    "        # Analyzing behaviors for each time group\n",
    "        all_metrics = []\n",
    "        for time_group, group_data in df.groupby('time_group', observed=False):\n",
    "            if not group_data.empty:\n",
    "                metrics = calculate_behavior_metrics(group_data)\n",
    "                for behavior, behavior_metrics in metrics.items():\n",
    "                    all_metrics.append({\n",
    "                        'Time Group': time_group,\n",
    "                        'Behavior': behavior,\n",
    "                        **behavior_metrics\n",
    "                    })\n",
    "\n",
    "        # DataFrame + save results\n",
    "        analysis_df = pd.DataFrame(all_metrics)\n",
    "        analysis_file_path = os.path.join(analysis_dir, f'analysis_{file_name}')\n",
    "        analysis_df.to_csv(analysis_file_path, index=False)\n",
    "        print(f'Saved analysis for {file_name} to {analysis_file_path}')\n",
    "\n",
    "print('Behavior analysis completed for all files.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T18:05:20.351720Z",
     "start_time": "2025-01-11T18:05:20.233750Z"
    }
   },
   "id": "220534d037cacb24",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cohort Comparisons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4130516229ebd8ff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cohort summary for group 'Combined' to ../processed_dataset/project_ACC_MiniscopeSNI_Male_Psilo_1Week/figures/behavior_timepoint_comparison/cohort_summaries/Combined_cohort_summary.csv\n",
      "Cohort summaries created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = f'../processed_dataset/{project_name}/figures/behavior_timepoint_comparison'\n",
    "cohort_summary_dir = f'../processed_dataset/{project_name}/figures/behavior_timepoint_comparison/cohort_summaries'\n",
    "os.makedirs(cohort_summary_dir, exist_ok=True)\n",
    "\n",
    "def aggregate_cohort_data(group_name, condition_list):\n",
    "    all_metrics = []\n",
    "    \n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.csv'):\n",
    "            if any(condition in file_name for condition in condition_list):\n",
    "                file_path = os.path.join(input_dir, file_name)\n",
    "                file_data = pd.read_csv(file_path)\n",
    "                all_metrics.append(file_data)\n",
    "    \n",
    "    if not all_metrics:\n",
    "        print(f\"No matching files found for group '{group_name}' with conditions {condition_list}\")\n",
    "        return None\n",
    "    \n",
    "    combined_data = pd.concat(all_metrics, ignore_index=True)\n",
    "    \n",
    "    summary = combined_data.groupby(['Time Group', 'Behavior']).agg({\n",
    "        'Fraction Time': ['mean', 'std'],  # Mean and standard deviation\n",
    "        'Bouts per Minute': ['mean', 'std'],\n",
    "        'Mean Bout Duration (s)': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    summary.columns = ['Time Group', 'Behavior', \n",
    "                       'Fraction Time (mean)', 'Fraction Time (std)',\n",
    "                       'Bouts per Minute (mean)', 'Bouts per Minute (std)',\n",
    "                       'Mean Bout Duration (mean)', 'Mean Bout Duration (std)']\n",
    "    \n",
    "    summary = summary.dropna(subset=[\n",
    "        'Fraction Time (mean)', \n",
    "        'Bouts per Minute (mean)', \n",
    "        'Mean Bout Duration (mean)'\n",
    "    ], how='all')\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "for group_name in selected_groups:\n",
    "\n",
    "    summary = aggregate_cohort_data(group_name, selected_conditions)\n",
    "    if summary is not None:\n",
    "\n",
    "        summary_file_path = os.path.join(cohort_summary_dir, f'{group_name}_cohort_summary.csv')\n",
    "        summary.to_csv(summary_file_path, index=False)\n",
    "        print(f\"Saved cohort summary for group '{group_name}' to {summary_file_path}\")\n",
    "\n",
    "print(\"Cohort summaries created.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T18:05:21.140042Z",
     "start_time": "2025-01-11T18:05:21.129740Z"
    }
   },
   "id": "ec0bed5c41605550",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COMPLETE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5973ad0d3ed3430e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
